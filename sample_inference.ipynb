{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9dc5f2b-ec9d-4438-b6b6-e9969dcc11d2",
   "metadata": {},
   "source": [
    "# Florence-2-large sample usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126eebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codespaces 环境缺失包导入\n",
    "# ! python3 -m pip install --upgrade pip\n",
    "# ! pip3 install transformers\n",
    "# ! pip3 install Pillow requests\n",
    "# ! pip install einops\n",
    "# ! pip install timm\n",
    "# ! pip install flash_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install einops timm flash_attn\n",
    "# ! pip install --upgrade jupyter ipywidgets\n",
    "# ! jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "! pip install ipywidgets\n",
    "! jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "! jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5afc4f-7540-4dce-8d18-ad74db6a22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCausalLM  \n",
    "from PIL import Image\n",
    "import requests\n",
    "import copy\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b356b-630d-4b89-8139-1995e31822e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'microsoft/Florence-2-large'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval().cuda()\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d43102-ba85-4438-b971-063d8677129b",
   "metadata": {},
   "source": [
    "## define the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427f95b-3c6e-4834-b08f-8af1a38306b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example(task_prompt, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(\n",
    "      input_ids=inputs[\"input_ids\"].cuda(),\n",
    "      pixel_values=inputs[\"pixel_values\"].cuda(),\n",
    "      max_new_tokens=1024,\n",
    "      early_stopping=False,\n",
    "      do_sample=False,\n",
    "      num_beams=3,\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text, \n",
    "        task=task_prompt, \n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "\n",
    "    return parsed_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5492d-83ad-44b1-a06b-4c55ecc8abb4",
   "metadata": {},
   "source": [
    "## init image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd464a8e-0f93-465e-a58e-ec69fe739db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35894f7-42b9-48ee-9718-b2edd01722e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2530935-e270-44d2-bb38-5b2b88ebb0df",
   "metadata": {},
   "source": [
    "## Run pre-defined tasks without additional inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbea76d-1b31-45b4-b3d9-ea8ada73bd7c",
   "metadata": {},
   "source": [
    "### Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0804b7f-c6a3-44c5-a5cf-0493e070a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<CAPTION>'\n",
    "run_example(task_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11700ca3-54dc-4de0-836e-9814cee3a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<DETAILED_CAPTION>'\n",
    "run_example(task_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a8ec2-447f-400d-b545-d0577b6bdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<MORE_DETAILED_CAPTION>'\n",
    "run_example(task_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230bbeed-4f85-4f35-9223-80b7b4e38da1",
   "metadata": {},
   "source": [
    "### Object detection\n",
    "\n",
    "OD results format: \n",
    "{'\\<OD>':\n",
    "    {\n",
    "    'bboxes': [[x1, y1, x2, y2], ...], \n",
    "    'labels': ['label1', 'label2', ...]\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a68a3-669d-423c-bd6c-29194ca16e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<OD>'\n",
    "results = run_example(task_prompt)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4db86-1e27-467a-b86c-9d8595d5ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.patches as patches  \n",
    "def plot_bbox(image, data):\n",
    "   # Create a figure and axes  \n",
    "    fig, ax = plt.subplots()  \n",
    "      \n",
    "    # Display the image  \n",
    "    ax.imshow(image)  \n",
    "      \n",
    "    # Plot each bounding box  \n",
    "    for bbox, label in zip(data['bboxes'], data['labels']):  \n",
    "        # Unpack the bounding box coordinates  \n",
    "        x1, y1, x2, y2 = bbox  \n",
    "        # Create a Rectangle patch  \n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')  \n",
    "        # Add the rectangle to the Axes  \n",
    "        ax.add_patch(rect)  \n",
    "        # Annotate the label  \n",
    "        plt.text(x1, y1, label, color='white', fontsize=8, bbox=dict(facecolor='red', alpha=0.5))  \n",
    "      \n",
    "    # Remove the axis ticks and labels  \n",
    "    ax.axis('off')  \n",
    "      \n",
    "    # Show the plot  \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7001f0-b0dd-44da-aae8-f77a3737a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<OD>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50558829-44ed-4dec-8512-5ba12efb0bdd",
   "metadata": {},
   "source": [
    "### Dense region caption\n",
    "\n",
    "Dense region caption results format: \n",
    "{'\\<DENSE_REGION_CAPTION>': {'bboxes': [[x1, y1, x2, y2], ...], 'labels': ['label1', 'label2', ...]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326bf03-51c8-4784-ae02-3d32ab97fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<DENSE_REGION_CAPTION>'\n",
    "results = run_example(task_prompt)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad8c29-44cb-4532-bf45-806c344760a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<DENSE_REGION_CAPTION>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea7184-03da-4ede-b1ef-ba458ef2fdd3",
   "metadata": {},
   "source": [
    "### Region proposal\n",
    "\n",
    "Region proposal results format: \n",
    "{'<REGION_PROPOSAL>' : {'bboxes': [[x1, y1, x2, y2], ...], 'labels': ['', '', ...]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26e9a9-8662-491e-a6da-0d9ad3a4a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<REGION_PROPOSAL>'\n",
    "results = run_example(task_prompt)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43817b0b-89d0-4160-8299-d4a3e4b5cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<REGION_PROPOSAL>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d31fa-20cf-470d-af1b-a125fc46f9e7",
   "metadata": {},
   "source": [
    "## Run pre-defined tasks that requires additional inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f342e2c-4fd0-4705-876c-198bd3320ab6",
   "metadata": {},
   "source": [
    "### Phrase Grounding\n",
    "Phrase grounding results format: \n",
    "{'\\<CAPTION_TO_PHRASE_GROUNDING>': {'bboxes': [[x1, y1, x2, y2], ...], 'labels': ['', '', ...]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a5f79-9290-4d1a-bf4f-16f1b5aaf197",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<CAPTION_TO_PHRASE_GROUNDING>'\n",
    "results = run_example(task_prompt, text_input=\"A green car parked in front of a yellow building.\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e9231-18ad-4838-ae16-3f2fa4d062d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<CAPTION_TO_PHRASE_GROUNDING>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd75b13-b113-4a4b-acea-5a8562a10ed2",
   "metadata": {},
   "source": [
    "### Referring expression segmentation\n",
    "\n",
    "Referring expression segmentation results format: \n",
    "{'\\<REFERRING_EXPRESSION_SEGMENTATION>': {'Polygons': [[[polygon]], ...], 'labels': ['', '', ...]}}, one object is represented by a list of polygons. each polygon is [x1, y1, x2, y2, ..., xn, yn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6411cf-f46f-4eab-9476-9a5641a75a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<REFERRING_EXPRESSION_SEGMENTATION>'\n",
    "results = run_example(task_prompt, text_input=\"a green car\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d70c16-233f-4495-bebc-31a0260d3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont \n",
    "import random\n",
    "import numpy as np\n",
    "colormap = ['blue','orange','green','purple','brown','pink','gray','olive','cyan','red',\n",
    "            'lime','indigo','violet','aqua','magenta','coral','gold','tan','skyblue']\n",
    "def draw_polygons(image, prediction, fill_mask=False):  \n",
    "    \"\"\"  \n",
    "    Draws segmentation masks with polygons on an image.  \n",
    "  \n",
    "    Parameters:  \n",
    "    - image_path: Path to the image file.  \n",
    "    - prediction: Dictionary containing 'polygons' and 'labels' keys.  \n",
    "                  'polygons' is a list of lists, each containing vertices of a polygon.  \n",
    "                  'labels' is a list of labels corresponding to each polygon.  \n",
    "    - fill_mask: Boolean indicating whether to fill the polygons with color.  \n",
    "    \"\"\"  \n",
    "    # Load the image  \n",
    "   \n",
    "    draw = ImageDraw.Draw(image)  \n",
    "      \n",
    "   \n",
    "    # Set up scale factor if needed (use 1 if not scaling)  \n",
    "    scale = 1  \n",
    "      \n",
    "    # Iterate over polygons and labels  \n",
    "    for polygons, label in zip(prediction['polygons'], prediction['labels']):  \n",
    "        color = random.choice(colormap)  \n",
    "        fill_color = random.choice(colormap) if fill_mask else None  \n",
    "          \n",
    "        for _polygon in polygons:  \n",
    "            _polygon = np.array(_polygon).reshape(-1, 2)  \n",
    "            if len(_polygon) < 3:  \n",
    "                print('Invalid polygon:', _polygon)  \n",
    "                continue  \n",
    "              \n",
    "            _polygon = (_polygon * scale).reshape(-1).tolist()  \n",
    "              \n",
    "            # Draw the polygon  \n",
    "            if fill_mask:  \n",
    "                draw.polygon(_polygon, outline=color, fill=fill_color)  \n",
    "            else:  \n",
    "                draw.polygon(_polygon, outline=color)  \n",
    "              \n",
    "            # Draw the label text  \n",
    "            draw.text((_polygon[0] + 8, _polygon[1] + 2), label, fill=color)  \n",
    "  \n",
    "    # Save or display the image  \n",
    "    #image.show()  # Display the image  \n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6b429-74ac-4226-be23-94b69242fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = copy.deepcopy(image)\n",
    "draw_polygons(output_image, results['<REFERRING_EXPRESSION_SEGMENTATION>'], fill_mask=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed56632-9052-4c4e-9426-f8538889cb6a",
   "metadata": {},
   "source": [
    "### region to segmentation\n",
    "\n",
    "\n",
    "with additional region as inputs, format is '\\<loc_x1>\\<loc_y1>\\<loc_x2>\\<loc_y2>', [x1, y1, x2, y2] is the quantized corrdinates in [0, 999]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed60a42-78ff-455c-b0d6-a3e25c0d801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<REGION_TO_SEGMENTATION>'\n",
    "results = run_example(task_prompt, text_input=\"<loc_702><loc_575><loc_866><loc_772>\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36876be-d9a2-4601-9c37-704224237ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = copy.deepcopy(image)\n",
    "draw_polygons(output_image, results['<REGION_TO_SEGMENTATION>'], fill_mask=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3accf12e-3441-4d3e-86e3-d5755601d7ce",
   "metadata": {},
   "source": [
    "### Open vocabulary detection\n",
    "\n",
    "open vocabulary detection can detect both objects and ocr texts. \n",
    "\n",
    "results format: \n",
    "\n",
    "{ '\\<OPEN_VOCABULARY_DETECTION>': {'bboxes': [[x1, y1, x2, y2], [x1, y1, x2, y2], ...]], 'bboxes_labels': ['label_1', 'label_2', ..],\n",
    "'polygons': [[[x1, y1, x2, y2, ..., xn, yn], [x1, y1, ..., xn, yn]], ...], 'polygons_labels': ['label_1', 'label_2', ...]\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43333b69-5484-4c16-b3cf-331d74c36780",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<OPEN_VOCABULARY_DETECTION>'\n",
    "results = run_example(task_prompt, text_input=\"a green car\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2965e-c621-4c33-86db-72e8c85c491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_od_format(data):  \n",
    "    \"\"\"  \n",
    "    Converts a dictionary with 'bboxes' and 'bboxes_labels' into a dictionary with separate 'bboxes' and 'labels' keys.  \n",
    "  \n",
    "    Parameters:  \n",
    "    - data: The input dictionary with 'bboxes', 'bboxes_labels', 'polygons', and 'polygons_labels' keys.  \n",
    "  \n",
    "    Returns:  \n",
    "    - A dictionary with 'bboxes' and 'labels' keys formatted for object detection results.  \n",
    "    \"\"\"  \n",
    "    # Extract bounding boxes and labels  \n",
    "    bboxes = data.get('bboxes', [])  \n",
    "    labels = data.get('bboxes_labels', [])  \n",
    "      \n",
    "    # Construct the output format  \n",
    "    od_results = {  \n",
    "        'bboxes': bboxes,  \n",
    "        'labels': labels  \n",
    "    }  \n",
    "      \n",
    "    return od_results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89801c1e-6fcf-44e1-87f6-12162bb9a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_results  = convert_to_od_format(results['<OPEN_VOCABULARY_DETECTION>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76424b2-ca13-4773-9506-66bc5eb1d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, bbox_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ffcf4-4404-4b6d-aee8-6c055da51301",
   "metadata": {},
   "source": [
    "### region to texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6b602-faea-448b-992e-12b55741ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<REGION_TO_CATEGORY>'\n",
    "results = run_example(task_prompt, text_input=\"<loc_52><loc_332><loc_932><loc_774>\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6081c-751c-47bd-a931-99337861b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<REGION_TO_DESCRIPTION>'\n",
    "results = run_example(task_prompt, text_input=\"<loc_52><loc_332><loc_932><loc_774>\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee1c41-0e99-41e8-b647-373cf84aa6a7",
   "metadata": {},
   "source": [
    "## ocr related tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996738d-e8ab-4223-ad61-cb0f97658f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://ecx.images-amazon.com/images/I/51UUzBDAMsL.jpg?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fadf9-bbb6-48f0-9222-cbd4d611bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478371e-9ca9-444a-8ef1-c30be4b9ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<OCR>'\n",
    "run_example(task_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e659469-9b0e-4dec-bec0-917b08a03622",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<OCR_WITH_REGION>'\n",
    "results = run_example(task_prompt)\n",
    "print(results)\n",
    "# ocr results format\n",
    "# {'OCR_WITH_REGION': {'quad_boxes': [[x1, y1, x2, y2, x3, y3, x4, y4], ...], 'labels': ['text1', ...]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d068b-2787-441a-a1c6-ddc0df402d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ocr_bboxes(image, prediction):\n",
    "    scale = 1\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    bboxes, labels = prediction['quad_boxes'], prediction['labels']\n",
    "    for box, label in zip(bboxes, labels):\n",
    "        color = random.choice(colormap)\n",
    "        new_box = (np.array(box) * scale).tolist()\n",
    "        draw.polygon(new_box, width=3, outline=color)\n",
    "        draw.text((new_box[0]+8, new_box[1]+2),\n",
    "                    \"{}\".format(label),\n",
    "                    align=\"right\",\n",
    "        \n",
    "                    fill=color)\n",
    "    display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc232a-2771-4f34-b3c2-a2ff92d4df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = copy.deepcopy(image)\n",
    "draw_ocr_bboxes(output_image, results['<OCR_WITH_REGION>'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c654ffe-66d2-48e1-98eb-ab5aa6d460a4",
   "metadata": {},
   "source": [
    "## Cascaded tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9752c6-f4d3-47f0-9bed-05ad06afe126",
   "metadata": {},
   "source": [
    "### Caption + Phrase Grounding \n",
    "\n",
    "results format: \n",
    "\n",
    "{\n",
    " '\\<CAPTION': pure_text, \n",
    "{'\\<CAPTION_TO_PHRASE_GROUNDING>': {'bboxes': [[x1, y1, x2, y2], ...], 'labels': ['', '', ...]}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b59013-e15d-403b-9171-3989ab6f190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e999741-297b-40e8-a1db-b0a718abb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<CAPTION>'\n",
    "results = run_example(task_prompt)\n",
    "text_input = results[task_prompt]\n",
    "task_prompt = '<CAPTION_TO_PHRASE_GROUNDING>'\n",
    "results = run_example(task_prompt, text_input)\n",
    "results['<CAPTION>'] = text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a2c37-6cf3-4814-bfe2-073d9a55532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fb9f8-7af1-49d7-837c-e4c11057e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<CAPTION_TO_PHRASE_GROUNDING>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6791895-df97-4538-ba21-4e8802415e3c",
   "metadata": {},
   "source": [
    "### Detailed Caption + Phrase Grounding \n",
    "\n",
    "results format: \n",
    "\n",
    "{\n",
    " '\\<DETAILED_CAPTION': pure_text, \n",
    "{'\\<CAPTION_TO_PHRASE_GROUNDING>': {'bboxes': [[x1, y1, x2, y2], ...], 'labels': ['', '', ...]}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f448c-28b2-4f22-902f-04ae8a159b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<DETAILED_CAPTION>'\n",
    "results = run_example(task_prompt)\n",
    "text_input = results[task_prompt]\n",
    "task_prompt = '<CAPTION_TO_PHRASE_GROUNDING>'\n",
    "results = run_example(task_prompt, text_input)\n",
    "results['<DETAILED_CAPTION>'] = text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b415c-7ccb-4270-9ddf-3235f3b57a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e9afb-5148-4314-86f7-f067aaecd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<CAPTION_TO_PHRASE_GROUNDING>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12497689-6c8f-4143-bc76-feca9d81d766",
   "metadata": {},
   "source": [
    "### More Detailed Caption + Phrase Grounding \n",
    "\n",
    "results format: \n",
    "\n",
    "{\n",
    " '\\<MORE_DETAILED_CAPTION': pure_text, \n",
    "{'\\<CAPTION_TO_PHRASE_GROUNDING>': {'bboxes': [[x1, y1, x2, y2], ...], 'labels': ['', '', ...]}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207af84-f92a-4325-b3d9-059e6c8624d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '<MORE_DETAILED_CAPTION>'\n",
    "results = run_example(task_prompt)\n",
    "text_input = results[task_prompt]\n",
    "task_prompt = '<CAPTION_TO_PHRASE_GROUNDING>'\n",
    "results = run_example(task_prompt, text_input)\n",
    "results['<MORE_DETAILED_CAPTION>'] = text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6417253-d6f2-4c79-a9fa-3cdc125c6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4db16-d9c4-49ec-878a-13acffffe99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bbox(image, results['<CAPTION_TO_PHRASE_GROUNDING>'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
